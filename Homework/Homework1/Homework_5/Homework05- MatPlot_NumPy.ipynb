{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcbdf77d-9d46-4ae3-bbd9-a6dcb8f76da6",
   "metadata": {},
   "source": [
    "# Homework #5 - MatPlot and NumPy\n",
    "\n",
    "\n",
    "\n",
    "#Part 1 Mat Plot Lib\n",
    "\n",
    "Using Matplotlib create the following graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16079d3e-c29d-4aac-b033-9aa4f6d72759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inports Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c902889-a006-4948-91d3-c49a910b61b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e1e3a8-1b51-4b05-b20c-51f57ac1ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897447d4-6a06-40b7-aff5-d5470f7d69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fffe1c02-1904-43aa-b2e9-cbac627ccd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a71d6-d331-4720-a89f-84716c623c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e4d5ba-5d06-46d7-8c08-55d29398ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d Plot - Bar Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ef0e37b-989a-4ee1-a3f6-fddad08e88aa",
   "metadata": {},
   "source": [
    "# Part 2 - Num Py\n",
    "Like a dictionary, we can create a structured array in Numpy\n",
    "\n",
    "```python\n",
    "data = np.array([\n",
    "    (\"Billy\", 32, 6),\n",
    "    (\"Bob\", 15, 20),\n",
    "    (\"Jo\", 80, 100),\n",
    "    (\"Goku\", 38, 9001),],\n",
    "    dtype=[(\"name\", str, 10), \n",
    "           (\"age\", int), \n",
    "           (\"power\", int)])\n",
    "```\n",
    "\n",
    "Using the following file https://www.kaggle.com/datasets/gregorut/videogamesales\n",
    "\n",
    "Create and sort the data by Name, Year, and NA_Sales\n",
    "\n",
    "Do not use pandas\n",
    "\n",
    "You can use this to help start you on your way\n",
    "https://stackoverflow.com/questions/57785790/construct-structured-numpy-array-from-a-file\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e696e893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\valfo\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46cffebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f8441b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function loadtxt in module numpy:\n",
      "\n",
      "loadtxt(fname, dtype=<class 'float'>, comments='#', delimiter=None, converters=None, skiprows=0, usecols=None, unpack=False, ndmin=0, encoding='bytes', max_rows=None, *, quotechar=None, like=None)\n",
      "    Load data from a text file.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    fname : file, str, pathlib.Path, list of str, generator\n",
      "        File, filename, list, or generator to read.  If the filename\n",
      "        extension is ``.gz`` or ``.bz2``, the file is first decompressed. Note\n",
      "        that generators must return bytes or strings. The strings\n",
      "        in a list or produced by a generator are treated as lines.\n",
      "    dtype : data-type, optional\n",
      "        Data-type of the resulting array; default: float.  If this is a\n",
      "        structured data-type, the resulting array will be 1-dimensional, and\n",
      "        each row will be interpreted as an element of the array.  In this\n",
      "        case, the number of columns used must match the number of fields in\n",
      "        the data-type.\n",
      "    comments : str or sequence of str or None, optional\n",
      "        The characters or list of characters used to indicate the start of a\n",
      "        comment. None implies no comments. For backwards compatibility, byte\n",
      "        strings will be decoded as 'latin1'. The default is '#'.\n",
      "    delimiter : str, optional\n",
      "        The character used to separate the values. For backwards compatibility,\n",
      "        byte strings will be decoded as 'latin1'. The default is whitespace.\n",
      "\n",
      "        .. versionchanged:: 1.23.0\n",
      "           Only single character delimiters are supported. Newline characters\n",
      "           cannot be used as the delimiter.\n",
      "\n",
      "    converters : dict or callable, optional\n",
      "        Converter functions to customize value parsing. If `converters` is\n",
      "        callable, the function is applied to all columns, else it must be a\n",
      "        dict that maps column number to a parser function.\n",
      "        See examples for further details.\n",
      "        Default: None.\n",
      "\n",
      "        .. versionchanged:: 1.23.0\n",
      "           The ability to pass a single callable to be applied to all columns\n",
      "           was added.\n",
      "\n",
      "    skiprows : int, optional\n",
      "        Skip the first `skiprows` lines, including comments; default: 0.\n",
      "    usecols : int or sequence, optional\n",
      "        Which columns to read, with 0 being the first. For example,\n",
      "        ``usecols = (1,4,5)`` will extract the 2nd, 5th and 6th columns.\n",
      "        The default, None, results in all columns being read.\n",
      "\n",
      "        .. versionchanged:: 1.11.0\n",
      "            When a single column has to be read it is possible to use\n",
      "            an integer instead of a tuple. E.g ``usecols = 3`` reads the\n",
      "            fourth column the same way as ``usecols = (3,)`` would.\n",
      "    unpack : bool, optional\n",
      "        If True, the returned array is transposed, so that arguments may be\n",
      "        unpacked using ``x, y, z = loadtxt(...)``.  When used with a\n",
      "        structured data-type, arrays are returned for each field.\n",
      "        Default is False.\n",
      "    ndmin : int, optional\n",
      "        The returned array will have at least `ndmin` dimensions.\n",
      "        Otherwise mono-dimensional axes will be squeezed.\n",
      "        Legal values: 0 (default), 1 or 2.\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "    encoding : str, optional\n",
      "        Encoding used to decode the inputfile. Does not apply to input streams.\n",
      "        The special value 'bytes' enables backward compatibility workarounds\n",
      "        that ensures you receive byte arrays as results if possible and passes\n",
      "        'latin1' encoded strings to converters. Override this value to receive\n",
      "        unicode arrays and pass strings as input to converters.  If set to None\n",
      "        the system default is used. The default value is 'bytes'.\n",
      "\n",
      "        .. versionadded:: 1.14.0\n",
      "    max_rows : int, optional\n",
      "        Read `max_rows` rows of content after `skiprows` lines. The default is\n",
      "        to read all the rows. Note that empty rows containing no data such as\n",
      "        empty lines and comment lines are not counted towards `max_rows`,\n",
      "        while such lines are counted in `skiprows`.\n",
      "\n",
      "        .. versionadded:: 1.16.0\n",
      "\n",
      "        .. versionchanged:: 1.23.0\n",
      "            Lines containing no data, including comment lines (e.g., lines\n",
      "            starting with '#' or as specified via `comments`) are not counted\n",
      "            towards `max_rows`.\n",
      "    quotechar : unicode character or None, optional\n",
      "        The character used to denote the start and end of a quoted item.\n",
      "        Occurrences of the delimiter or comment characters are ignored within\n",
      "        a quoted item. The default value is ``quotechar=None``, which means\n",
      "        quoting support is disabled.\n",
      "\n",
      "        If two consecutive instances of `quotechar` are found within a quoted\n",
      "        field, the first is treated as an escape character. See examples.\n",
      "\n",
      "        .. versionadded:: 1.23.0\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Data read from the text file.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    load, fromstring, fromregex\n",
      "    genfromtxt : Load data with missing values handled as specified.\n",
      "    scipy.io.loadmat : reads MATLAB data files\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    This function aims to be a fast reader for simply formatted files.  The\n",
      "    `genfromtxt` function provides more sophisticated handling of, e.g.,\n",
      "    lines with missing values.\n",
      "\n",
      "    Each row in the input text file must have the same number of values to be\n",
      "    able to read all values. If all rows do not have same number of values, a\n",
      "    subset of up to n columns (where n is the least number of values present\n",
      "    in all rows) can be read by specifying the columns via `usecols`.\n",
      "\n",
      "    .. versionadded:: 1.10.0\n",
      "\n",
      "    The strings produced by the Python float.hex method can be used as\n",
      "    input for floats.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from io import StringIO   # StringIO behaves like a file object\n",
      "    >>> c = StringIO(\"0 1\\n2 3\")\n",
      "    >>> np.loadtxt(c)\n",
      "    array([[0., 1.],\n",
      "           [2., 3.]])\n",
      "\n",
      "    >>> d = StringIO(\"M 21 72\\nF 35 58\")\n",
      "    >>> np.loadtxt(d, dtype={'names': ('gender', 'age', 'weight'),\n",
      "    ...                      'formats': ('S1', 'i4', 'f4')})\n",
      "    array([(b'M', 21, 72.), (b'F', 35, 58.)],\n",
      "          dtype=[('gender', 'S1'), ('age', '<i4'), ('weight', '<f4')])\n",
      "\n",
      "    >>> c = StringIO(\"1,0,2\\n3,0,4\")\n",
      "    >>> x, y = np.loadtxt(c, delimiter=',', usecols=(0, 2), unpack=True)\n",
      "    >>> x\n",
      "    array([1., 3.])\n",
      "    >>> y\n",
      "    array([2., 4.])\n",
      "\n",
      "    The `converters` argument is used to specify functions to preprocess the\n",
      "    text prior to parsing. `converters` can be a dictionary that maps\n",
      "    preprocessing functions to each column:\n",
      "\n",
      "    >>> s = StringIO(\"1.618, 2.296\\n3.141, 4.669\\n\")\n",
      "    >>> conv = {\n",
      "    ...     0: lambda x: np.floor(float(x)),  # conversion fn for column 0\n",
      "    ...     1: lambda x: np.ceil(float(x)),  # conversion fn for column 1\n",
      "    ... }\n",
      "    >>> np.loadtxt(s, delimiter=\",\", converters=conv)\n",
      "    array([[1., 3.],\n",
      "           [3., 5.]])\n",
      "\n",
      "    `converters` can be a callable instead of a dictionary, in which case it\n",
      "    is applied to all columns:\n",
      "\n",
      "    >>> s = StringIO(\"0xDE 0xAD\\n0xC0 0xDE\")\n",
      "    >>> import functools\n",
      "    >>> conv = functools.partial(int, base=16)\n",
      "    >>> np.loadtxt(s, converters=conv)\n",
      "    array([[222., 173.],\n",
      "           [192., 222.]])\n",
      "\n",
      "    This example shows how `converters` can be used to convert a field\n",
      "    with a trailing minus sign into a negative number.\n",
      "\n",
      "    >>> s = StringIO('10.01 31.25-\\n19.22 64.31\\n17.57- 63.94')\n",
      "    >>> def conv(fld):\n",
      "    ...     return -float(fld[:-1]) if fld.endswith(b'-') else float(fld)\n",
      "    ...\n",
      "    >>> np.loadtxt(s, converters=conv)\n",
      "    array([[ 10.01, -31.25],\n",
      "           [ 19.22,  64.31],\n",
      "           [-17.57,  63.94]])\n",
      "\n",
      "    Using a callable as the converter can be particularly useful for handling\n",
      "    values with different formatting, e.g. floats with underscores:\n",
      "\n",
      "    >>> s = StringIO(\"1 2.7 100_000\")\n",
      "    >>> np.loadtxt(s, converters=float)\n",
      "    array([1.e+00, 2.7e+00, 1.e+05])\n",
      "\n",
      "    This idea can be extended to automatically handle values specified in\n",
      "    many different formats:\n",
      "\n",
      "    >>> def conv(val):\n",
      "    ...     try:\n",
      "    ...         return float(val)\n",
      "    ...     except ValueError:\n",
      "    ...         return float.fromhex(val)\n",
      "    >>> s = StringIO(\"1, 2.5, 3_000, 0b4, 0x1.4000000000000p+2\")\n",
      "    >>> np.loadtxt(s, delimiter=\",\", converters=conv, encoding=None)\n",
      "    array([1.0e+00, 2.5e+00, 3.0e+03, 1.8e+02, 5.0e+00])\n",
      "\n",
      "    Note that with the default ``encoding=\"bytes\"``, the inputs to the\n",
      "    converter function are latin-1 encoded byte strings. To deactivate the\n",
      "    implicit encoding prior to conversion, use ``encoding=None``\n",
      "\n",
      "    >>> s = StringIO('10.01 31.25-\\n19.22 64.31\\n17.57- 63.94')\n",
      "    >>> conv = lambda x: -float(x[:-1]) if x.endswith('-') else float(x)\n",
      "    >>> np.loadtxt(s, converters=conv, encoding=None)\n",
      "    array([[ 10.01, -31.25],\n",
      "           [ 19.22,  64.31],\n",
      "           [-17.57,  63.94]])\n",
      "\n",
      "    Support for quoted fields is enabled with the `quotechar` parameter.\n",
      "    Comment and delimiter characters are ignored when they appear within a\n",
      "    quoted item delineated by `quotechar`:\n",
      "\n",
      "    >>> s = StringIO('\"alpha, #42\", 10.0\\n\"beta, #64\", 2.0\\n')\n",
      "    >>> dtype = np.dtype([(\"label\", \"U12\"), (\"value\", float)])\n",
      "    >>> np.loadtxt(s, dtype=dtype, delimiter=\",\", quotechar='\"')\n",
      "    array([('alpha, #42', 10.), ('beta, #64',  2.)],\n",
      "          dtype=[('label', '<U12'), ('value', '<f8')])\n",
      "\n",
      "    Quoted fields can be separated by multiple whitespace characters:\n",
      "\n",
      "    >>> s = StringIO('\"alpha, #42\"       10.0\\n\"beta, #64\" 2.0\\n')\n",
      "    >>> dtype = np.dtype([(\"label\", \"U12\"), (\"value\", float)])\n",
      "    >>> np.loadtxt(s, dtype=dtype, delimiter=None, quotechar='\"')\n",
      "    array([('alpha, #42', 10.), ('beta, #64',  2.)],\n",
      "          dtype=[('label', '<U12'), ('value', '<f8')])\n",
      "\n",
      "    Two consecutive quote characters within a quoted field are treated as a\n",
      "    single escaped character:\n",
      "\n",
      "    >>> s = StringIO('\"Hello, my name is \"\"Monty\"\"!\"')\n",
      "    >>> np.loadtxt(s, dtype=\"U\", delimiter=\",\", quotechar='\"')\n",
      "    array('Hello, my name is \"Monty\"!', dtype='<U26')\n",
      "\n",
      "    Read subset of columns when all rows do not contain equal number of values:\n",
      "\n",
      "    >>> d = StringIO(\"1 2\\n2 4\\n3 9 12\\n4 16 20\")\n",
      "    >>> np.loadtxt(d, usecols=(0, 1))\n",
      "    array([[ 1.,  2.],\n",
      "           [ 2.,  4.],\n",
      "           [ 3.,  9.],\n",
      "           [ 4., 16.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.loadtxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0db37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.loadtxt(\"vgsales.csv\",dtype={'data_names':('Name','Year','NA_Sales'),'formats':('f4', 'U50','f4')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432fed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.loadtxt(\"vgsales.csv\",delimiter=',',dtype=[('Name', 'U50'), ('Year', 'i4'), ('NA_Sales', 'f4')],skiprows=1)\n",
    "#('Name','f'),('Year','i'),('NA_Sales','f')},{'formats':('f4', 'i50','f4')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c34a909a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "the dtype passed requires 3 columns but 11 were found at row 1; use `usecols` to select a subset and avoid this error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m dtype \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU50\u001b[39m\u001b[38;5;124m'\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi4\u001b[39m\u001b[38;5;124m'\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNA_Sales\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the CSV file\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgsales.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n",
      "File \u001b[1;32mc:\\Users\\valfo\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1371\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1373\u001b[0m arr \u001b[38;5;241m=\u001b[39m _read(fname, dtype\u001b[38;5;241m=\u001b[39mdtype, comment\u001b[38;5;241m=\u001b[39mcomment, delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[0;32m   1374\u001b[0m             converters\u001b[38;5;241m=\u001b[39mconverters, skiplines\u001b[38;5;241m=\u001b[39mskiprows, usecols\u001b[38;5;241m=\u001b[39musecols,\n\u001b[0;32m   1375\u001b[0m             unpack\u001b[38;5;241m=\u001b[39munpack, ndmin\u001b[38;5;241m=\u001b[39mndmin, encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   1376\u001b[0m             max_rows\u001b[38;5;241m=\u001b[39mmax_rows, quote\u001b[38;5;241m=\u001b[39mquotechar)\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32mc:\\Users\\valfo\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:1016\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1016\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _load_from_filelike(\n\u001b[0;32m   1017\u001b[0m         data, delimiter\u001b[38;5;241m=\u001b[39mdelimiter, comment\u001b[38;5;241m=\u001b[39mcomment, quote\u001b[38;5;241m=\u001b[39mquote,\n\u001b[0;32m   1018\u001b[0m         imaginary_unit\u001b[38;5;241m=\u001b[39mimaginary_unit,\n\u001b[0;32m   1019\u001b[0m         usecols\u001b[38;5;241m=\u001b[39musecols, skiplines\u001b[38;5;241m=\u001b[39mskiplines, max_rows\u001b[38;5;241m=\u001b[39mmax_rows,\n\u001b[0;32m   1020\u001b[0m         converters\u001b[38;5;241m=\u001b[39mconverters, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1021\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding, filelike\u001b[38;5;241m=\u001b[39mfilelike,\n\u001b[0;32m   1022\u001b[0m         byte_converters\u001b[38;5;241m=\u001b[39mbyte_converters)\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "\u001b[1;31mValueError\u001b[0m: the dtype passed requires 3 columns but 11 were found at row 1; use `usecols` to select a subset and avoid this error"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Correct dtype specification\n",
    "dtype = [('Name', 'U50'), ('Year', 'i4'), ('NA_Sales', 'f4')]\n",
    "\n",
    "# Load the CSV file\n",
    "data = np.loadtxt(\"vgsales.csv\", dtype=dtype, delimiter=',', skiprows=1)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23f17bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If a structured dtype is used, the number of columns in `usecols` must match the effective number of fields. But 1 usecols were given and the number of fields is 3.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m dtype_ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU50\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      3\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi4\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      4\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNA_Sales\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m ]\n\u001b[1;32m----> 6\u001b[0m np\u001b[38;5;241m.\u001b[39mloadtxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgsales.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype_,delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m,usecols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\valfo\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1371\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1373\u001b[0m arr \u001b[38;5;241m=\u001b[39m _read(fname, dtype\u001b[38;5;241m=\u001b[39mdtype, comment\u001b[38;5;241m=\u001b[39mcomment, delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[0;32m   1374\u001b[0m             converters\u001b[38;5;241m=\u001b[39mconverters, skiplines\u001b[38;5;241m=\u001b[39mskiprows, usecols\u001b[38;5;241m=\u001b[39musecols,\n\u001b[0;32m   1375\u001b[0m             unpack\u001b[38;5;241m=\u001b[39munpack, ndmin\u001b[38;5;241m=\u001b[39mndmin, encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   1376\u001b[0m             max_rows\u001b[38;5;241m=\u001b[39mmax_rows, quote\u001b[38;5;241m=\u001b[39mquotechar)\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32mc:\\Users\\valfo\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:1016\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1016\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _load_from_filelike(\n\u001b[0;32m   1017\u001b[0m         data, delimiter\u001b[38;5;241m=\u001b[39mdelimiter, comment\u001b[38;5;241m=\u001b[39mcomment, quote\u001b[38;5;241m=\u001b[39mquote,\n\u001b[0;32m   1018\u001b[0m         imaginary_unit\u001b[38;5;241m=\u001b[39mimaginary_unit,\n\u001b[0;32m   1019\u001b[0m         usecols\u001b[38;5;241m=\u001b[39musecols, skiplines\u001b[38;5;241m=\u001b[39mskiplines, max_rows\u001b[38;5;241m=\u001b[39mmax_rows,\n\u001b[0;32m   1020\u001b[0m         converters\u001b[38;5;241m=\u001b[39mconverters, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1021\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding, filelike\u001b[38;5;241m=\u001b[39mfilelike,\n\u001b[0;32m   1022\u001b[0m         byte_converters\u001b[38;5;241m=\u001b[39mbyte_converters)\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "\u001b[1;31mTypeError\u001b[0m: If a structured dtype is used, the number of columns in `usecols` must match the effective number of fields. But 1 usecols were given and the number of fields is 3."
     ]
    }
   ],
   "source": [
    "dtype_ = [\n",
    "    ('Name', 'U50'),\n",
    "    ('Year', 'i4'),\n",
    "    ('NA_Sales', 'f4')\n",
    "]\n",
    "np.loadtxt(\"vgsales.csv\", dtype=dtype_,delimiter=',',usecols=3,skiprows=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59e0cc96-b400-4262-a1df-9bef56d1459b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "entry not a 2- or 3- tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m np\u001b[38;5;241m.\u001b[39mloadtxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgsales.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m'\u001b[39m:(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNA_Sales\u001b[39m\u001b[38;5;124m'\u001b[39m)})\n",
      "File \u001b[1;32mc:\\Users\\valfo\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1371\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1373\u001b[0m arr \u001b[38;5;241m=\u001b[39m _read(fname, dtype\u001b[38;5;241m=\u001b[39mdtype, comment\u001b[38;5;241m=\u001b[39mcomment, delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[0;32m   1374\u001b[0m             converters\u001b[38;5;241m=\u001b[39mconverters, skiplines\u001b[38;5;241m=\u001b[39mskiprows, usecols\u001b[38;5;241m=\u001b[39musecols,\n\u001b[0;32m   1375\u001b[0m             unpack\u001b[38;5;241m=\u001b[39munpack, ndmin\u001b[38;5;241m=\u001b[39mndmin, encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   1376\u001b[0m             max_rows\u001b[38;5;241m=\u001b[39mmax_rows, quote\u001b[38;5;241m=\u001b[39mquotechar)\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32mc:\\Users\\valfo\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:917\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma dtype must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 917\u001b[0m dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m    919\u001b[0m read_dtype_via_object_chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUM\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    921\u001b[0m         dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mU0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM8\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm8\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    922\u001b[0m     \u001b[38;5;66;03m# This is a legacy \"flexible\" dtype.  We do not truly support\u001b[39;00m\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;66;03m# parametric dtypes currently (no dtype discovery step in the core),\u001b[39;00m\n\u001b[0;32m    924\u001b[0m     \u001b[38;5;66;03m# but have to support these for backward compatibility.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\valfo\\anaconda3\\Lib\\site-packages\\numpy\\core\\_internal.py:62\u001b[0m, in \u001b[0;36m_usefields\u001b[1;34m(adict, align)\u001b[0m\n\u001b[0;32m     60\u001b[0m     names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 62\u001b[0m     names, formats, offsets, titles \u001b[38;5;241m=\u001b[39m _makenames_list(adict, align)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     formats \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\valfo\\anaconda3\\Lib\\site-packages\\numpy\\core\\_internal.py:32\u001b[0m, in \u001b[0;36m_makenames_list\u001b[1;34m(adict, align)\u001b[0m\n\u001b[0;32m     30\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(obj)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m n \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentry not a 2- or 3- tuple\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m obj[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m fname:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: entry not a 2- or 3- tuple"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.loadtxt(\"vgsales.csv\", dtype={'names':('rank', 'name', 'year', 'NA_Sales')})#, 'formats':('i', 'U', 'i', 'f')})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
